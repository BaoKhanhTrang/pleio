#!/usr/bin/env python3

'''
PLEIO: PLEIOtropy
Copyright(C) 2018 Cue Hyunkyu Lee 

PLEIO is command line framework to perform cross-disease meta-analyses
'''

#from framework.meta_analysis import *
from framework.parse import *
from framework.importance_sampling import importance_sampling
from framework.significance_estimation import cof_estimation, pvalue_estimation, pval_flattening 
from meta_code.variance_component import vcm_optimization
from meta_code.LS import LS, LS_p 
import numpy as np
import pandas as pd
import os, sys, traceback, argparse, time
import multiprocessing as mp
from itertools import product

codename = 'PLEIO'
__version__ = '1.0'
MASTHEAD = "************************************************************\n"
MASTHEAD += "* PLEIO({c})\n".format(c=codename)
MASTHEAD += "* Version {V}\n".format(V=__version__)
MASTHEAD += "* (C)2018 Cue H. Lee\n"
MASTHEAD += "* Seoul National University\n"
MASTHEAD += "* Unlicensed software\n"
MASTHEAD += "************************************************************\n"

def sec_to_str(t):
    '''Convert seconds to days:hours:minutes:seconds'''
    intervals = (('d', 86400), ('h', 3600), ('m', 60), ('s', 1), )
    f = ''
    for n, c in intervals:
        v = t // c
        if v:
            t -= v * c
            if c !=1:
                f += '{}{} '.format(round(v), n)
    return (f)


class Logger(object):
    '''
    Lightweight logging.
    TODO: replace with logging module

    '''
    def __init__(self, fh):
        self.log_fh = open(fh, 'w');

    def log(self, msg):
        '''
        Print to log file and stdout with a single command.

        '''
        print (msg, file = self.log_fh);
        print (msg);
        
    def mlog(self, msg):
        '''
        [ mutelog ] Print to log file and without stdout with a single command.

        '''
        print (msg, file = self.log_fh);

def sqrt_ginv (X, tol = 2.22044604925e-16**0.5):
    u,s,vh = np.linalg.svd(X)
    Positive = s > max(tol * s[0], 0)  
    if (all(Positive)):
        res=np.transpose(vh).dot(np.diag(1/s)**0.5).dot(np.transpose(u))
    elif (not any(Positive)): 
        res=np.array([0]*np.prod(X.shape)).reshape(X.shape)
    else:
        res=np.transpose(vh[:, Positive]).dot(np.diag(1/s[Positive])**0.5).dot(np.transpose(u[:, Positive]))
    return(res)

def is_pos_def(x):
    eigs = np.linalg.eigvals(x)
    return np.all(eigs > 0)


def run_vc_optimizer(x, sUt, Ce, ind):
    b = np.transpose(sUt).dot(np.array([x[i] for i in ind]));
    se = np.array([x[i+1] for i in ind]);
    K = np.transpose(sUt).dot(np.diag(se)).dot(Ce).dot(np.diag(se)).dot(sUt)
    return(vcm_optimization(b, K))

def LS_input_parser(x, Ce, ind):
    b = [x[i] for i in ind];
    se = [x[i+1] for i in ind];
    return(LS(b, se, Ce))

def _estimate_statistics(df_data, Sg, Ce, isf):
    n = np.size(Sg,1)
    ind = [i*2 for i in range(n)]
    sqrt_Sg_ginv = sqrt_ginv(Sg) 
    df_out = pd.DataFrame(index = df_data.index)
    df_out['pleio_stat'] = df_data.apply(lambda x: run_vc_optimizer(x.tolist(), sqrt_Sg_ginv, Ce, ind), axis=1)
    df_out['LS_stat'] = df_data.apply(lambda x: LS_input_parser(x.tolist(), Ce, ind), axis=1)
    p_functions = cof_estimation(isf);
    df_out['pleio_p'] = df_out.loc[:,'pleio_stat'].apply(lambda x: pvalue_estimation(x, p_functions));
    df_out['LS_p'] = df_out.loc[:,'LS_stat'].apply(lambda x: LS_p(x));
    return(df_out)

def _parallelize(meta_cain, func, args, isf): 
    data_split = np.array_split(meta_cain.metain, int(args.ncores))
    iterable = product(data_split, [meta_cain.Sg.values], [meta_cain.Ce.values], [isf])
    pool = mp.Pool(int(args.ncores))
    df_output = pd.concat(pool.starmap(func, iterable))
    pool.close()
    pool.join()
    return(df_output)

def read_input(infile, sgf, cef):
    class meta_class_array_object_generator(object):
        def __init__(self, metain_df, sg_df, ce_df, N_gwas, tlist):
            self.metain = metain_df;
            self.Sg = sg_df;
            self.Ce = ce_df;
            self.N_gwas = N_gwas;
            self.n = len(tlist);
            self.zero_prob = float(0.195);

    def read_mat(fn, LIST, name):
        df = pd.read_csv(fn,sep='\t', compression = 'infer'); 
        df.index = df.columns 
        df = df.loc[LIST,LIST]
        if not is_pos_def(df):
            print(name,'is not a positive definite matrix')
        return(df)

    metain_df = pd.read_csv(infile, sep='\t', compression = 'infer', index_col = ['SNP'])
    col = metain_df.columns.tolist()
    include = [col[i].split('_beta')[0] for i in range(len(col)) if i % 2 == 0]
    N_gwas = (metain_df.loc[:,[col[i] for i in range(len(col)) if i % 2 != 0]]).apply(lambda x: np.mean(1/float(x)**2))
    error_correlation_df = read_mat(cef,include,'error correlation matrix');
    genetic_covariance_df = read_mat(sgf,include,'genetic covariance matrix');
    meta_cain = meta_class_array_object_generator(metain_df, genetic_covariance_df, error_correlation_df, N_gwas, include)
    return(meta_cain)

def pleio(args,log):

   ### Read inputs as a class_array_object 
    if args.metain is not None:
        meta_cain = read_input(args.metain, args.sg, args.ce)

    if args.create:
        outdir = args.out;
        importance_sampling_f = os.path.join(outdir + '.isf'); 
        meta_cain.zero_prob = importance_sampling(args.nis, meta_cain.N_gwas, meta_cain.Sg, meta_cain.Ce, importance_sampling_f, args.ncores);
    else:
        quit('The feature has not been supported yet');
    
        
    summary = _parallelize(meta_cain, _estimate_statistics, args, importance_sampling_f);

    if args.pvalue_flattening:
        summary = pval_flattening(summary, meta_cain.N_gwas, meta_cain.Sg, meta_cain.Ce, args.ncores ,importance_sampling_f )
        #pval_flattening(summary, meta_cain.N_gwas, meta_cain.Sg, meta_cain.Ce, args.ncores ,importance_sampling_f )
    
    out_path = os.path.join(outdir+'.txt.gz');
    summary.to_csv(out_path, index = True, sep='\t', compression='gzip');

    quit('work done')


parser = argparse.ArgumentParser()
parser.add_argument('--out', default='output',type=str,
    help='Output file directory name. If --out is not set, PLEIO will use out as the '
    'default output directory.')
# Meta-analysis Flags
parser.add_argument('--metain', default=None, type=str,
    help='input file: file prefix of the meta input data.')
parser.add_argument('--sg', default=None, type=str,
    help='input file: file prefix of the genetic covariance matrix.')
parser.add_argument('--ce', default=None, type=str,
    help='input file: file prefix of the non-genetic correlation matrix.')
parser.add_argument('--isf', default=None, type=str,
    help='Filename Prefix for Estimated null-distribution cumulative densities. ')
parser.add_argument('--create', default = False, action='store_true',
    help='If this flag is set, PLEIO will run importance sampling and create new isf. ')
parser.add_argument('--nis', default = int(100000), type = int,
    help='Number of samples for importance sampling. ')
parser.add_argument('--pvalue_flattening', default = False, action= 'store_true',
    help='Flattening p-value distribution. This is necessary if you want to check lambda GC')
parser.add_argument('--parallel', default = False, action='store_true',
    help='If this flag is set, PLEIO will run parallel computing ')
parser.add_argument('--ncores', default = mp.cpu_count() - 2, type = int, 
    help='Number of cpu cores for parallel computing. PLEIO uses max(CPUs) as default.')
### To understand input file format
parser.add_argument('--snp', default='SNP', type=str,
    help='Name of SNP column (if not a name that ldsc understands). NB: case insensitive.')

if __name__ == '__main__':
    args = parser.parse_args()
    if args.out is None:
        raise ValueError('--out is required');
    
    log = Logger(args.out+'.log');

    try:
        defaults = vars(parser.parse_args(''));
        opts = vars(args);
        non_defaults = [x for x in opts.keys() if opts[x] != defaults[x]];
        header = MASTHEAD;
        header += 'Call: \n';
        header += './pleio.py \\\n';
        options = ['--'+x.replace('_','-')+' '+str(opts[x])+' \\' for x in non_defaults];
        header += '\n'.join(options).replace('True','').replace('False','');
        header = header[0:-1]+'\n';
        log.log(header);
        log.log('Beginning analysis at {T}'.format(T=time.ctime()));
        start_time = time.time()
        
        if args.metain is not None:
            if args.metain is None:
                raise ValueError('--input file should be defined')
            if args.metain is not None and args.sg is None or args.ce is None:
                raise ValueError('--metain need --sg and --ce flags to be defined')
            if args.create is not True and args.isf is None:
                raise ValueError('--create or --isf flag should be defined') 
            if (args.parallel == False):
                args.ncores = 1;
            
            pleio(args,log)

        else:
            print ('Error: no analysis selected.')
            print ('Use delpy.py -h for details.')

    except Exception:
        log.mlog(traceback.format_exc());
        raise

    finally:
        log.log('Analysis finished at {T}'.format(T=time.ctime()) )
        time_elapsed = round(time.time()-start_time,2)
        log.log('Total time elapsed: {T}'.format(T=sec_to_str(time_elapsed)))

## Sg and Rn should have same dimension
